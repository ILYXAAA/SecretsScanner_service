from fastapi import FastAPI, UploadFile, File, BackgroundTasks, HTTPException
from fastapi.responses import JSONResponse
from app.models import ScanRequest, PATTokenRequest, RulesContent, MultiScanRequest, MultiScanResponse, MultiScanResponseItem
from app.queue_worker import task_queue, start_worker, add_to_queue_background, add_multi_scan_to_queue, cleanup_executors
from app.model_loader import get_model_instance
from app.repo_utils import check_ref_and_resolve_git, check_ref_and_resolve_azure
import asyncio
import os
import aiofiles
from app.secure_save import encrypt_and_save, decrypt_from_file
from dotenv import load_dotenv
import signal
import sys

load_dotenv()

HubType = os.getenv("HubType")
app = FastAPI()

# Configuration
TOKEN_FILE = "Settings/pat_token.dat"
MAX_WORKERS = int(os.getenv("MAX_WORKERS", "10"))  # Increased default workers
RULES_PATH = "Settings/rules.yml"
EXCLUDED_EXTENSIONS_PATH = "Settings/excluded_extensions.yml"
EXCLUDED_FILES_PATH = "Settings/excluded_files.yml"
FP_FILE_PATH = "Settings/false-positive.yml"

# Global worker tasks list for cleanup
worker_tasks = []

# === PAT Token Endpoints ===

@app.post("/set-pat")
async def set_pat_token(payload: PATTokenRequest):
    if not payload.token:
        raise HTTPException(status_code=400, detail="Token is required")

    try:
        encrypt_and_save(text=payload.token, filename=TOKEN_FILE, key_name="PAT_KEY")
    except Exception as error:
        return {"status": "failed", "message": f"Error: {str(error)}"}
    
    return {"status": "success", "message": "PAT token saved"}

@app.get("/get-pat")
async def get_pat_token():
    try:
        if not os.path.exists(TOKEN_FILE):
            return {"status": "not_found", "message": "Token not set"}

        token = decrypt_from_file(TOKEN_FILE, key_name="PAT_KEY")

        if len(token) < 4:
            masked = "*" * len(token)
        else:
            masked = token[:4] + "*" * (len(token) - 4)
    except Exception as error:
        return {"status": "failed", "message": f"Error: {str(error)}"}
    return {"status": "success", "token": masked}

# === Application Lifecycle ===

@app.on_event("startup")
async def startup_event():
    """Initialize model and start concurrent workers"""
    global worker_tasks
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞ —Å {MAX_WORKERS} –≤–æ—Ä–∫–µ—Ä–∞–º–∏...")
    
    # Pre-load model in main process
    try:
        get_model_instance()
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    # Start concurrent workers
    for i in range(MAX_WORKERS):
        task = asyncio.create_task(start_worker())
        worker_tasks.append(task)
        print(f"‚úÖ –í–æ—Ä–∫–µ—Ä {i+1} –∑–∞–ø—É—â–µ–Ω")
    
    print(f"üéØ –°–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–æ–≤")

@app.on_event("shutdown")
async def shutdown_event():
    """Graceful shutdown"""
    global worker_tasks
    
    print("üõë –ù–∞—á–∏–Ω–∞—é –æ—Å—Ç–∞–Ω–æ–≤–∫—É —Å–µ—Ä–≤–∏—Å–∞...")
    
    try:
        # Cancel all worker tasks
        for task in worker_tasks:
            if not task.done():
                task.cancel()
        
        # Wait for tasks to complete with timeout
        if worker_tasks:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*worker_tasks, return_exceptions=True),
                    timeout=5.0
                )
            except asyncio.TimeoutError:
                print("‚ö†Ô∏è Timeout –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –≤–æ—Ä–∫–µ—Ä–æ–≤")
        
        # Cleanup executors
        try:
            await cleanup_executors()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ executors: {e}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ shutdown: {e}")
    finally:
        print("‚úÖ –°–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# === Health Check ===

@app.get("/health")
async def health():
    return {
        "status": "healthy", 
        "queue_size": task_queue.qsize(),
        "max_workers": MAX_WORKERS,
        "active_workers": len(worker_tasks),
        "supports_multi_scan": True
    }

# === Multi-Scanning Endpoint ===

@app.post("/multi_scan")
async def multi_scan(request: MultiScanRequest):
    """Process multiple repositories sequentially"""
    
    # Check queue capacity
    if task_queue.qsize() >= MAX_WORKERS * 2:
        return JSONResponse(status_code=429, content={
            "status": "queue_full",
            "message": f"–û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ ({task_queue.qsize()} –∑–∞–¥–∞—á). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "data": []
        })

    response_data = []
    all_resolved = True
    error_message = ""

    # Validate all repositories first
    for repo in request.repositories:
        try:
            if HubType.lower() == "github":
                exists, commit, message = await check_ref_and_resolve_git(repo.RepoUrl, repo.RefType, repo.Ref)
            else:
                exists, commit, message = await check_ref_and_resolve_azure(repo.RepoUrl, repo.RefType, repo.Ref)
            
            if exists:
                response_data.append(MultiScanResponseItem(
                    ProjectName=repo.ProjectName,
                    RefType=repo.RefType,
                    Ref=repo.Ref,
                    commit=commit
                ))
                print(f"‚úÖ Resolved {repo.ProjectName}: {commit[:6]}")
            else:
                all_resolved = False
                response_data.append(MultiScanResponseItem(
                    ProjectName=repo.ProjectName,
                    RefType=repo.RefType,
                    Ref=repo.Ref,
                    commit="not_found"
                ))
                print(f"‚ùå Failed to resolve {repo.ProjectName}: {message}")
                if not error_message:
                    error_message = message or f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ {repo.RefType} '{repo.Ref}'"
                    
        except Exception as e:
            all_resolved = False
            response_data.append(MultiScanResponseItem(
                ProjectName=repo.ProjectName,
                RefType=repo.RefType,
                Ref=repo.Ref,
                commit="not_found"
            ))
            print(f"‚ùå Error resolving {repo.ProjectName}: {e}")
            if not error_message:
                error_message = str(e)

    # Respond based on validation results
    if all_resolved:
        # Convert to format for queue
        multi_scan_items = []
        commits = []
        
        for repo, response_item in zip(request.repositories, response_data):
            multi_scan_items.append({
                "ProjectName": repo.ProjectName,
                "RepoUrl": repo.RepoUrl,
                "RefType": repo.RefType,
                "Ref": repo.Ref,
                "CallbackUrl": repo.CallbackUrl
            })
            commits.append(response_item.commit)
        
        # Add to queue for sequential processing
        await add_multi_scan_to_queue(multi_scan_items, commits)
        
        return JSONResponse(
            content={
                "status": "accepted",
                "message": "–ú—É–ª—å—Ç–∏—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å ‚úÖ",
                "data": [item.dict() for item in response_data]
            },
            status_code=200
        )
    else:
        return JSONResponse(
            content={
                "status": "validation_failed",
                "message": f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–∑–æ–ª–≤–∏—Ç—å –∫–æ–º–º–∏—Ç—ã: {error_message}",
                "data": [item.dict() for item in response_data]
            },
            status_code=400
        )

# === Scanning Endpoint ===

@app.post("/scan")
async def scan(request: ScanRequest):
    # Check queue capacity (allow some buffer over max workers)
    if task_queue.qsize() >= MAX_WORKERS * 2:
        return JSONResponse(status_code=429, content={
            "status": "queue_full",
            "RefType": request.RefType,
            "Ref": request.Ref,
            "message": f"–û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ ({task_queue.qsize()} –∑–∞–¥–∞—á). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        })

    try:
        # Validate reference exists and resolve to commit
        if HubType.lower() == "github":
            exists, commit, message = await check_ref_and_resolve_git(request.RepoUrl, request.RefType, request.Ref)
        else:
            exists, commit, message = await check_ref_and_resolve_azure(request.RepoUrl, request.RefType, request.Ref)
        
        if not exists:
            if message:
                return JSONResponse(status_code=400, content={
                    "status": "validation_failed",
                    "RefType": request.RefType,
                    "Ref": request.Ref,
                    "message": message
                })
            else:
                raise ValueError(f"{request.RefType} '{request.Ref}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {request.RepoUrl}")
        
        print(f"‚úÖ Commit resolved {commit[0:6]}.. –¥–ª—è {request.ProjectName}")

        # Add to queue for processing
        await add_to_queue_background(request, commit)
        
        response = JSONResponse(
            content={
                "status": "accepted",
                "RefType": request.RefType,
                "Ref": request.Ref,
                "commit": commit,
                "queue_position": task_queue.qsize(),
                "message": "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å ‚úÖ"
            },
            status_code=200
        )

        return response
    
    except ValueError as e:
        print(f"‚ùå –ó–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–∏–Ω—è—Ç - validation_failed: {e}")
        return JSONResponse(status_code=400, content={
            "status": "validation_failed",
            "RefType": request.RefType,
            "Ref": request.Ref,
            "message": str(e)
        })
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return JSONResponse(status_code=500, content={
            "status": "error",
            "RefType": request.RefType,
            "Ref": request.Ref,
            "message": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"
        })

###########################
# Rules.yml ###############
###########################
@app.get("/rules-info")
async def rules_info():
    if os.path.exists(RULES_PATH):
        stat = os.stat(RULES_PATH)
        return {
            "exists": True,
            "size": stat.st_size,
            "modified": stat.st_mtime,
            "path": os.path.abspath(RULES_PATH)
        }
    return {
        "exists": False,
        "size": 0,
        "modified": 0.0,
        "path": os.path.abspath(RULES_PATH)
    }

@app.get("/get-rules")
async def get_rules():
    try:
        if not os.path.exists(RULES_PATH):
            return JSONResponse(status_code=404, content={"status": "failed", "message": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"})
        
        async with aiofiles.open(RULES_PATH, mode='r', encoding='utf-8') as f:
            content = await f.read()

        return {"status": "success", "rules": content}
    
    except Exception as e:
        return JSONResponse(status_code=500, content={
            "status": "failed",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
        })

@app.post("/update-rules")
async def update_rules(data: RulesContent):
    try:
        info = await update_rules_file(data.content)
        return {"status": "success", **info}
    except Exception as e:
        return {
            "status": "failed",
            "message": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}",
            "filename": RULES_PATH,
            "size": 0
        }
    
async def update_rules_file(content: str):
    # –ó–∞–º–µ–Ω—è–µ–º \r\n –∏ \r –Ω–∞ \n (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
    normalized_content = content.replace('\r\n', '\n').replace('\r', '\n')

    async with aiofiles.open(RULES_PATH, 'w', encoding='utf-8') as out_file:
        await out_file.write(normalized_content)

    size = os.path.getsize(RULES_PATH)
    return {
        "message": f"–§–∞–π–ª {RULES_PATH} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω",
        "filename": RULES_PATH,
        "size": size
    }

###########################
# excluded_files.yml ######
###########################
@app.get("/excluded-files-info")
async def excluded_files_info():
    if os.path.exists(EXCLUDED_FILES_PATH):
        stat = os.stat(EXCLUDED_FILES_PATH)
        return {
            "exists": True,
            "size": stat.st_size,
            "modified": stat.st_mtime,
            "path": os.path.abspath(EXCLUDED_FILES_PATH)
        }
    return {
        "exists": False,
        "size": 0,
        "modified": 0.0,
        "path": os.path.abspath(EXCLUDED_FILES_PATH)
    }

@app.get("/get-excluded-files")
async def get_excluded_files():
    try:
        if not os.path.exists(EXCLUDED_FILES_PATH):
            return JSONResponse(status_code=404, content={"status": "failed", "message": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"})
        
        async with aiofiles.open(EXCLUDED_FILES_PATH, mode='r', encoding='utf-8') as f:
            content = await f.read()

        return {"status": "success", "excluded_files": content}
    
    except Exception as e:
        return JSONResponse(status_code=500, content={
            "status": "failed",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
        })

@app.post("/update-excluded-files")
async def update_excluded_files(data: RulesContent):
    try:
        info = await do_update_excluded_files(data.content)
        return {"status": "success", **info}
    except Exception as e:
        return {
            "status": "failed",
            "message": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}",
            "filename": EXCLUDED_FILES_PATH,
            "size": 0
        }
    
async def do_update_excluded_files(content: str):
    normalized_content = content.replace('\r\n', '\n').replace('\r', '\n')

    async with aiofiles.open(EXCLUDED_FILES_PATH, 'w', encoding='utf-8') as out_file:
        await out_file.write(normalized_content)

    size = os.path.getsize(EXCLUDED_FILES_PATH)
    return {
        "message": f"–§–∞–π–ª {EXCLUDED_FILES_PATH} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω",
        "filename": EXCLUDED_FILES_PATH,
        "size": size
    }

###########################
# excluded_extensions.yml #
###########################
@app.get("/excluded-extensions-info")
async def excluded_extensions_info():
    if os.path.exists(EXCLUDED_EXTENSIONS_PATH):
        stat = os.stat(EXCLUDED_EXTENSIONS_PATH)
        return {
            "exists": True,
            "size": stat.st_size,
            "modified": stat.st_mtime,
            "path": os.path.abspath(EXCLUDED_EXTENSIONS_PATH)
        }
    return {
        "exists": False,
        "size": 0,
        "modified": 0.0,
        "path": os.path.abspath(EXCLUDED_EXTENSIONS_PATH)
    }

@app.get("/get-excluded-extensions")
async def get_excluded_extensions():
    try:
        if not os.path.exists(EXCLUDED_EXTENSIONS_PATH):
            return JSONResponse(status_code=404, content={"status": "failed", "message": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"})
        
        async with aiofiles.open(EXCLUDED_EXTENSIONS_PATH, mode='r', encoding='utf-8') as f:
            content = await f.read()

        return {"status": "success", "excluded_extensions": content}
    
    except Exception as e:
        return JSONResponse(status_code=500, content={
            "status": "failed",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
        })

@app.post("/update-excluded-extensions")
async def update_excluded_extensions(data: RulesContent):
    try:
        info = await do_update_excluded_extensions(data.content)
        return {"status": "success", **info}
    except Exception as e:
        return {
            "status": "failed",
            "message": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}",
            "filename": EXCLUDED_EXTENSIONS_PATH,
            "size": 0
        }
    
async def do_update_excluded_extensions(content: str):
    normalized_content = content.replace('\r\n', '\n').replace('\r', '\n')

    async with aiofiles.open(EXCLUDED_EXTENSIONS_PATH, 'w', encoding='utf-8') as out_file:
        await out_file.write(normalized_content)

    size = os.path.getsize(EXCLUDED_EXTENSIONS_PATH)
    return {
        "message": f"–§–∞–π–ª {EXCLUDED_EXTENSIONS_PATH} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω",
        "filename": EXCLUDED_EXTENSIONS_PATH,
        "size": size
    }

# Remove custom signal handlers - let uvicorn handle them



##########################################
# False-Positive Rules.yml ###############
##########################################
@app.get("/rules-fp-info")
async def rules_fp_info():
    if os.path.exists(FP_FILE_PATH):
        stat = os.stat(FP_FILE_PATH)
        return {
            "exists": True,
            "size": stat.st_size,
            "modified": stat.st_mtime,
            "path": os.path.abspath(FP_FILE_PATH)
        }
    return {
        "exists": False,
        "size": 0,
        "modified": 0.0,
        "path": os.path.abspath(FP_FILE_PATH)
    }

@app.get("/get-fp-rules")
async def get_fp_rules():
    try:
        if not os.path.exists(FP_FILE_PATH):
            return JSONResponse(status_code=404, content={"status": "failed", "message": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"})
        
        async with aiofiles.open(FP_FILE_PATH, mode='r', encoding='utf-8') as f:
            content = await f.read()

        return {"status": "success", "rules": content}
    
    except Exception as e:
        return JSONResponse(status_code=500, content={
            "status": "failed",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
        })

@app.post("/update-fp-rules")
async def update_fp_rules(data: RulesContent):
    try:
        info = await update_fp_rules_file(data.content)
        return {"status": "success", **info}
    except Exception as e:
        return {
            "status": "failed",
            "message": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}",
            "filename": FP_FILE_PATH,
            "size": 0
        }
    
async def update_fp_rules_file(content: str):
    # –ó–∞–º–µ–Ω—è–µ–º \r\n –∏ \r –Ω–∞ \n (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
    normalized_content = content.replace('\r\n', '\n').replace('\r', '\n')

    async with aiofiles.open(FP_FILE_PATH, 'w', encoding='utf-8') as out_file:
        await out_file.write(normalized_content)

    size = os.path.getsize(FP_FILE_PATH)
    return {
        "message": f"–§–∞–π–ª {FP_FILE_PATH} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω",
        "filename": FP_FILE_PATH,
        "size": size
    }
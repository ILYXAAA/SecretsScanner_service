import os
import time
import joblib
import random
import csv
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import pickle
import logging
from logging.handlers import RotatingFileHandler

# Setup logging function
def setup_logging(console_mode=False):
    log_file = '../secrets_scanner_service.log' if console_mode else 'secrets_scanner_service.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger("model_loader")

# Default logger for import mode
logger = setup_logging(console_mode=False)

class SecretClassifier:
    _instance = None
    model = None
    vectorizer = None

    def __init__(self, console_mode=False):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ –∑–∞–ø—É—Å–∫–∞
        if console_mode:
            self.MODEL_PATH = "../Model/secret_detector_model.pkl"
            self.VECTORIZER_PATH = "../Model/vectorizer.pkl"
            self.SECRETS_DATASET = "../Datasets/Dataset_Secrets.txt"
            self.NOT_SECRETS_DATASET = "../Datasets/Dataset_NonSecrets.txt"
            self.TEST_CSV_PATH = "../TestModel/TestModel.csv"
        else:
            self.MODEL_PATH = "Model/secret_detector_model.pkl"
            self.VECTORIZER_PATH = "Model/vectorizer.pkl"
            self.SECRETS_DATASET = "Datasets/Dataset_Secrets.txt"
            self.NOT_SECRETS_DATASET = "Datasets/Dataset_NonSecrets.txt"
            self.TEST_CSV_PATH = "TestModel/TestModel.csv"

    def __new__(cls, console_mode=False):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.__init__(console_mode)
            cls._instance._load_or_train_model()
        return cls._instance

    def _load_or_train_model(self):
        start_time = time.time()

        if os.path.exists(self.MODEL_PATH) and os.path.exists(self.VECTORIZER_PATH):
            self.model = joblib.load(self.MODEL_PATH)
            self.vectorizer = joblib.load(self.VECTORIZER_PATH)
            logger.info(f"–ú–æ–¥–µ–ª—å –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞ {(time.time() - start_time):.2f} —Å–µ–∫.")
        else:
            logger.warning(f"–§–∞–π–ª—ã –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ.")
            self._train_model()
            logger.info(f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∑–∞ {(time.time() - start_time):.2f} —Å–µ–∫.")

    def _train_model(self):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        with open(self.SECRETS_DATASET, "r", encoding="utf-8") as f:
            secrets = f.read().splitlines()

        with open(self.NOT_SECRETS_DATASET, "r", encoding="utf-8") as f:
            non_secrets = f.read().splitlines()

        X = secrets + non_secrets
        y = [1] * len(secrets) + [0] * len(non_secrets)

        combined = list(zip(X, y))
        random.shuffle(combined)
        X, y = zip(*combined)

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        self.vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5))
        X_train_vec = self.vectorizer.fit_transform(X_train)

        self.model = LogisticRegression(max_iter=1000)
        self.model.fit(X_train_vec, y_train)

        # Ensure directories exist
        os.makedirs(os.path.dirname(self.MODEL_PATH), exist_ok=True)
        
        joblib.dump(self.model, self.MODEL_PATH)
        joblib.dump(self.vectorizer, self.VECTORIZER_PATH)

    def retrain_model(self):
        """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –Ω—É–ª—è"""
        print("üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        start_time = time.time()
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if os.path.exists(self.MODEL_PATH):
            os.remove(self.MODEL_PATH)
        if os.path.exists(self.VECTORIZER_PATH):
            os.remove(self.VECTORIZER_PATH)
            
        self._train_model()
        
        training_time = time.time() - start_time
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ –∑–∞ {training_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._evaluate_model(use_internal_test=True)

    def _evaluate_model(self, use_internal_test=True, csv_path=None):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –≤–Ω–µ—à–Ω–µ–º CSV —Ñ–∞–π–ª–µ"""
        start_time = time.time()
        
        if csv_path and os.path.exists(csv_path):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω–µ—à–Ω–∏–π CSV —Ñ–∞–π–ª
            print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞—é —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {csv_path}")
            
            try:
                test_data = []
                with open(csv_path, 'r', encoding='utf-8') as csvfile:
                    reader = csv.DictReader(csvfile)
                    for row in reader:
                        secret_value = row.get('secret_value', '') or ''
                        secret_type = row.get('secret_type', '') or ''
                        
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                        if secret_value:
                            secret_value = secret_value.strip()
                        if secret_type:
                            secret_type = secret_type.strip()
                        
                        if secret_value and secret_type:
                            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—É—é –º–µ—Ç–∫—É –≤ —á–∏—Å–ª–æ–≤—É—é
                            true_label = 1 if secret_type.lower() == 'secret' else 0
                            test_data.append({
                                'text': secret_value,
                                'true_label': true_label,
                                'true_label_str': secret_type
                            })
                
                if not test_data:
                    print("‚ùå –í CSV —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è!")
                    return
                    
                X = [item['text'] for item in test_data]
                y = [item['true_label'] for item in test_data]
                y_str = [item['true_label_str'] for item in test_data]
                
                print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_data)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ CSV —Ñ–∞–π–ª–∞: {e}")
                return
                
        elif use_internal_test:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
            try:
                with open(self.SECRETS_DATASET, "r", encoding="utf-8") as f:
                    secrets = f.read().splitlines()

                with open(self.NOT_SECRETS_DATASET, "r", encoding="utf-8") as f:
                    non_secrets = f.read().splitlines()

                X = secrets + non_secrets
                y = [1] * len(secrets) + [0] * len(non_secrets)
                y_str = ['Secret'] * len(secrets) + ['NotSecret'] * len(non_secrets)

                combined = list(zip(X, y, y_str))
                random.shuffle(combined)
                X, y, y_str = zip(*combined)

                X_train, X_test, y_train, y_test, y_str_train, y_str_test = train_test_split(
                    X, y, y_str, test_size=0.2, random_state=42)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                X = X_test
                y = y_test
                y_str = y_str_test
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {e}")
                return
        else:
            print("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è!")
            return
        
        try:
            # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–±—ã—Å—Ç—Ä–æ!)
            print("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            X_vec = self.vectorizer.transform(X)
            y_pred = self.model.predict(X_vec)
            y_proba = self.model.predict_proba(X_vec)
            
            processing_time = time.time() - start_time
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(y, y_pred)
            precision = precision_score(y, y_pred, zero_division=0)
            recall = recall_score(y, y_pred, zero_division=0)
            f1 = f1_score(y, y_pred, zero_division=0)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
            secrets_count = sum(1 for label in y if label == 1)
            non_secrets_count = len(y) - secrets_count
            correct_predictions = sum(1 for true, pred in zip(y, y_pred) if true == pred)
            
            # –û—à–∏–±–∫–∏
            false_positives = sum(1 for true, pred in zip(y, y_pred) if true == 0 and pred == 1)
            false_negatives = sum(1 for true, pred in zip(y, y_pred) if true == 1 and pred == 0)
            
            # –°–æ–±–∏—Ä–∞–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            wrong_predictions = []
            for i, (text, true_label, pred_label, proba) in enumerate(zip(X, y, y_pred, y_proba)):
                if true_label != pred_label:
                    confidence = proba[1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ "Secret"
                    wrong_predictions.append({
                        'secret': text,
                        'expected': y_str[i],
                        'prediction': 'Secret' if pred_label == 1 else 'NotSecret',
                        'confidence': round(confidence, 3)
                    })
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if csv_path:
                print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ô –ü–†–û–í–ï–†–ö–ò")
                print("=" * 50)
            else:
                print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
                print("-" * 40)
                
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {processing_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(y)}")
            print(f"üî¥ –°–µ–∫—Ä–µ—Ç—ã –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ: {secrets_count}")
            print(f"üü¢ –ù–µ-—Å–µ–∫—Ä–µ—Ç—ã –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ: {non_secrets_count}")
            print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–º–µ—á–µ–Ω–æ: {correct_predictions} –∏–∑ {len(y)}")
            print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {accuracy:.1%} ({accuracy:.3f})")
            print(f"üìà Precision: {precision:.1%} ({precision:.3f})")
            print(f"üîç Recall: {recall:.1%} ({recall:.3f})")
            print(f"‚öñÔ∏è  F1-Score: {f1:.1%} ({f1:.3f})")
            print(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {len(y)/processing_time:.1f} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π/—Å–µ–∫")
            
            print(f"\nüîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–®–ò–ë–û–ö:")
            print(f"   False Positives (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–∞–∫ —Å–µ–∫—Ä–µ—Ç—ã): {false_positives}")
            print(f"   False Negatives (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å–µ–∫—Ä–µ—Ç—ã): {false_negatives}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ CSV (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
            if csv_path and wrong_predictions:
                wrong_csv_path = "../TestModel/wrong_secrets.csv"
                try:
                    os.makedirs(os.path.dirname(wrong_csv_path), exist_ok=True)
                    
                    with open(wrong_csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                        fieldnames = ['secret', 'expected', 'prediction', 'confidence']
                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                        writer.writeheader()
                        writer.writerows(wrong_predictions)
                    
                    print(f"üíæ –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {wrong_csv_path}")
                    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: {len(wrong_predictions)}")
                    
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å –æ—à–∏–±–∫–∞–º–∏: {e}")
            elif csv_path and not wrong_predictions:
                print("üéâ –í—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—ã–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏!")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            import traceback
            traceback.print_exc()

    def automatic_test_from_csv(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ CSV —Ñ–∞–π–ª–µ"""
        print("\nü§ñ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê –ú–û–î–ï–õ–ò")
        print("-" * 40)
        
        if not os.path.exists(self.TEST_CSV_PATH):
            print(f"‚ùå –§–∞–π–ª {self.TEST_CSV_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return
            
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é _evaluate_model
        self._evaluate_model(use_internal_test=False, csv_path=self.TEST_CSV_PATH)

    def get_model_info(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö"""
        info = {}
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
        try:
            if os.path.exists(self.SECRETS_DATASET):
                with open(self.SECRETS_DATASET, "r", encoding="utf-8") as f:
                    secrets_count = len(f.read().splitlines())
                info['secrets_dataset_size'] = secrets_count
            else:
                info['secrets_dataset_size'] = 0
                
            if os.path.exists(self.NOT_SECRETS_DATASET):
                with open(self.NOT_SECRETS_DATASET, "r", encoding="utf-8") as f:
                    non_secrets_count = len(f.read().splitlines())
                info['non_secrets_dataset_size'] = non_secrets_count
            else:
                info['non_secrets_dataset_size'] = 0
                
            info['total_dataset_size'] = info.get('secrets_dataset_size', 0) + info.get('non_secrets_dataset_size', 0)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {e}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        if self.model is not None:
            info['model_type'] = type(self.model).__name__
            if hasattr(self.model, 'C'):
                info['model_C'] = self.model.C
            if hasattr(self.model, 'max_iter'):
                info['model_max_iter'] = self.model.max_iter
                
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–µ
        if self.vectorizer is not None:
            info['vectorizer_type'] = type(self.vectorizer).__name__
            info['vectorizer_analyzer'] = getattr(self.vectorizer, 'analyzer', 'unknown')
            info['vectorizer_ngram_range'] = getattr(self.vectorizer, 'ngram_range', 'unknown')
            if hasattr(self.vectorizer, 'vocabulary_'):
                info['vocabulary_size'] = len(self.vectorizer.vocabulary_)
        
        # –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç–∏
        memory_info = self.get_model_memory_usage()
        info.update(memory_info)
        
        return info

    def get_model_memory_usage(self):
        """Get accurate memory usage of loaded model components"""
        memory_info = {}
        
        if self.model is not None:
            # Serialize model to measure size
            model_bytes = pickle.dumps(self.model)
            memory_info['model_mb'] = len(model_bytes) / (1024 * 1024)
        
        if self.vectorizer is not None:
            # Serialize vectorizer to measure size
            vectorizer_bytes = pickle.dumps(self.vectorizer)
            memory_info['vectorizer_mb'] = len(vectorizer_bytes) / (1024 * 1024)
            
            # Additional vectorizer details
            if hasattr(self.vectorizer, 'vocabulary_'):
                memory_info['vocabulary_size'] = len(self.vectorizer.vocabulary_)
        
        memory_info['total_mb'] = memory_info.get('model_mb', 0) + memory_info.get('vectorizer_mb', 0)
        
        return memory_info

    def predict_single(self, text: str, context: str = None):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if not text.strip():
            return None
            
        start_time = time.time()
        
        try:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            X_vec = self.vectorizer.transform([text])
            pred_text = self.model.predict(X_vec)[0]
            proba_text = self.model.predict_proba(X_vec)[0]
            confidence_text = proba_text[1]
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç, –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –¥–ª—è –Ω–µ–≥–æ
            if context and context.strip():
                X_context_vec = self.vectorizer.transform([context])
                pred_context = self.model.predict(X_context_vec)[0]
                proba_context = self.model.predict_proba(X_context_vec)[0]
                confidence_context = proba_context[1]
                
                # –£—Å—Ä–µ–¥–Ω—è–µ–º confidence
                confidence = (confidence_text + confidence_context) / 2
                # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Å–Ω–æ–≤—ã–≤–∞–µ–º –Ω–∞ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                pred = int(confidence > 0.5)
                
                prediction_details = {
                    'text_prediction': bool(pred_text),
                    'text_confidence': round(confidence_text, 3),
                    'context_prediction': bool(pred_context),
                    'context_confidence': round(confidence_context, 3),
                    'averaged_confidence': True
                }
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ —Ç–µ–∫—Å—Ç—É
                confidence = confidence_text
                pred = pred_text
                prediction_details = {
                    'text_prediction': bool(pred_text),
                    'text_confidence': round(confidence_text, 3),
                    'context_prediction': None,
                    'context_confidence': None,
                    'averaged_confidence': False
                }
            
            processing_time = time.time() - start_time
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º severity
            if "–°–¢–†–û–ö–ê –ù–ï –°–ö–ê–ù–ò–†–û–í–ê–õ–ê–°–¨ —Ç.–∫. –µ—ë –¥–ª–∏–Ω–∞" in text or "–§–ê–ô–õ –ù–ï –í–´–í–ï–î–ï–ù –ü–û–õ–ù–û–°–¢–¨–Æ —Ç.–∫." in text:
                severity = "Potential"
                confidence = 0.50
            else:
                if confidence > 0.7:
                    severity = "High"
                else:
                    severity = "Potential"
            
            return {
                'text': text,
                'context': context,
                'is_secret': bool(pred),
                'confidence': round(confidence, 3),
                'severity': severity,
                'processing_time_ms': round(processing_time * 1000, 2),
                'prediction_details': prediction_details
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            return {
                'text': text,
                'context': context,
                'error': str(e)
            }

    def filter_secrets(self, ProjectName, secrets: list[dict]) -> list[dict]:
        classification_start = time.time()
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ª–æ–≤–∞—Ä—è –≤ —Å–ø–∏—Å–∫–µ secrets –ø–æ –ø–æ–ª—è–º "secret" –∏ "context".
        –ï—Å–ª–∏ –æ–±–∞ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç, —É—Å—Ä–µ–¥–Ω—è–µ—Ç confidence –º–µ–∂–¥—É –Ω–∏–º–∏.
        –ó–∞–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–µ "severity":
        - "High" –¥–ª—è —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö —Å–µ–∫—Ä–µ—Ç–æ–≤ (confidence > 0.7)
        - "Potential" –¥–ª—è –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –ø–æ–ª–µ–º "severity" –∏ "confidence".
        """
        if not secrets:
            return secrets
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        secret_texts = [item.get("secret", "") for item in secrets]
        context_texts = [item.get("context", "") for item in secrets]
        
        if not secret_texts:
            return secrets

        try:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å–µ–∫—Ä–µ—Ç–æ–≤
            X_secret_vec = self.vectorizer.transform(secret_texts)
            preds_secret = self.model.predict(X_secret_vec)
            probs_secret = self.model.predict_proba(X_secret_vec)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
            context_predictions = []
            context_probabilities = []
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–ø—É—Å—Ç—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
            non_empty_contexts = [ctx if ctx and ctx.strip() else None for ctx in context_texts]
            
            if any(ctx is not None for ctx in non_empty_contexts):
                # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                contexts_to_predict = [ctx for ctx in non_empty_contexts if ctx is not None]
                
                if contexts_to_predict:
                    X_context_vec = self.vectorizer.transform(contexts_to_predict)
                    context_preds = self.model.predict(X_context_vec)
                    context_probs = self.model.predict_proba(X_context_vec)
                    
                    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å None –¥–ª—è –ø—É—Å—Ç—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
                    context_idx = 0
                    for ctx in non_empty_contexts:
                        if ctx is not None:
                            context_predictions.append(context_preds[context_idx])
                            context_probabilities.append(context_probs[context_idx])
                            context_idx += 1
                        else:
                            context_predictions.append(None)
                            context_probabilities.append(None)
                else:
                    context_predictions = [None] * len(secrets)
                    context_probabilities = [None] * len(secrets)
            else:
                context_predictions = [None] * len(secrets)
                context_probabilities = [None] * len(secrets)

            for i, (item, pred_secret, proba_secret) in enumerate(zip(secrets, preds_secret, probs_secret)):
                confidence_secret = proba_secret[1]  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1 (—á—Ç–æ —ç—Ç–æ —Å–µ–∫—Ä–µ—Ç)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
                pred_context = context_predictions[i] if i < len(context_predictions) else None
                proba_context = context_probabilities[i] if i < len(context_probabilities) else None
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                item["secret_confidence"] = round(confidence_secret, 3)
                item["secret_prediction"] = bool(pred_secret)
                
                if pred_context is not None and proba_context is not None:
                    confidence_context = proba_context[1]
                    item["context_confidence"] = round(confidence_context, 3)
                    item["context_prediction"] = bool(pred_context)
                    
                    # –£—Å—Ä–µ–¥–Ω—è–µ–º confidence
                    final_confidence = (confidence_secret + confidence_context) / 2
                    item["confidence_averaged"] = True
                    
                    #logger.info(f"Secret conf: {confidence_secret:.3f}, Context conf: {confidence_context:.3f}, Avg: {final_confidence:.3f}")
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ confidence —Å–µ–∫—Ä–µ—Ç–∞
                    final_confidence = confidence_secret
                    item["context_confidence"] = None
                    item["context_prediction"] = None
                    item["confidence_averaged"] = False
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
                if "–°–¢–†–û–ö–ê –ù–ï –°–ö–ê–ù–ò–†–û–í–ê–õ–ê–°–¨ —Ç.–∫. –µ—ë –¥–ª–∏–Ω–∞" in item["secret"] or "–§–ê–ô–õ –ù–ï –í–´–í–ï–î–ï–ù –ü–û–õ–ù–û–°–¢–¨–Æ —Ç.–∫." in item["secret"]:
                    item["confidence"] = 0.50
                    item["severity"] = "Potential"
                else:
                    item["confidence"] = round(final_confidence, 2)
                    
                    if final_confidence > 0.7:
                        item["severity"] = "High"
                        #logger.info(f"Set HIGH for final confidence {final_confidence:.3f}")
                    else:
                        item["severity"] = "Potential"
                        #logger.info(f"Set POTENTIAL for final confidence {final_confidence:.3f}")
                                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            # Fallback: mark all as High severity
            for item in secrets:
                item["confidence"] = 1.00
                if not item.get("severity"):
                    item["severity"] = "High"

        classification_time = time.time() - classification_start
        logger.info(f"[{ProjectName}] –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {len(secrets)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–≤—Ä–µ–º—è: {classification_time:.2f}—Å)")
        return secrets

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ FastAPI
def get_model_instance():
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ (thread-safe)"""
    return SecretClassifier(console_mode=False)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
def filter_secrets_in_process(ProjectName, secrets_list: list[dict]) -> list[dict]:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ"""
    try:
        classifier = SecretClassifier(console_mode=False)
        return classifier.filter_secrets(ProjectName, secrets_list)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        # Fallback: mark all as High severity
        for item in secrets_list:
            if not item.get("severity"):
                item["severity"] = "High"
        return secrets_list


def show_menu():
    """–ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
    print("\n" + "="*50)
    print("ü§ñ –ú–ï–ù–ï–î–ñ–ï–† –ú–û–î–ï–õ–ò SECRETS CLASSIFIER")
    print("="*50)
    print("1. üîÑ –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
    print("2. üìä –ü–æ–∫–∞–∑–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")
    print("3. üß™ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å")
    print("4. ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
    print("5. üö™ –í—ã—Ö–æ–¥")
    print("="*50)


def show_model_info(classifier):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
    print("\nüìã –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò")
    print("-" * 30)
    
    info = classifier.get_model_info()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
    print(f"üìÅ –î–∞—Ç–∞—Å–µ—Ç—ã:")
    print(f"   ‚Ä¢ –°–µ–∫—Ä–µ—Ç—ã: {info.get('secrets_dataset_size', 'N/A')} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"   ‚Ä¢ –ù–µ —Å–µ–∫—Ä–µ—Ç—ã: {info.get('non_secrets_dataset_size', 'N/A')} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"   ‚Ä¢ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {info.get('total_dataset_size', 'N/A')} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
    print(f"\nü§ñ –ú–æ–¥–µ–ª—å:")
    print(f"   ‚Ä¢ –¢–∏–ø: {info.get('model_type', 'N/A')}")
    if 'model_C' in info:
        print(f"   ‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä C: {info['model_C']}")
    if 'model_max_iter' in info:
        print(f"   ‚Ä¢ –ú–∞–∫—Å. –∏—Ç–µ—Ä–∞—Ü–∏–π: {info['model_max_iter']}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–µ
    print(f"\nüî§ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä:")
    print(f"   ‚Ä¢ –¢–∏–ø: {info.get('vectorizer_type', 'N/A')}")
    print(f"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä: {info.get('vectorizer_analyzer', 'N/A')}")
    print(f"   ‚Ä¢ N-gram –¥–∏–∞–ø–∞–∑–æ–Ω: {info.get('vectorizer_ngram_range', 'N/A')}")
    print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {info.get('vocabulary_size', 'N/A')}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏
    print(f"\nüíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:")
    print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {info.get('model_mb', 0):.2f} –ú–ë")
    print(f"   ‚Ä¢ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä: {info.get('vectorizer_mb', 0):.2f} –ú–ë")
    print(f"   ‚Ä¢ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {info.get('total_mb', 0):.2f} –ú–ë")


def test_model(classifier):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("-" * 30)
    print("–í–≤–µ–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –≤—ã—Ö–æ–¥–∞):")
    print("–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.")
    print("-" * 50)
    
    while True:
        try:
            text = input("\n> –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç: ").strip()
            
            if not text:
                print("üëã –í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
                break
            
            context = input("> –í–≤–µ–¥–∏—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ): ").strip()
            if not context:
                context = None
                
            result = classifier.predict_single(text, context)
            
            if result is None:
                print("‚ö†Ô∏è  –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                continue
                
            if 'error' in result:
                print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                continue
            
            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
            print(f"   üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {'üî¥ –°–ï–ö–†–ï–¢' if result['is_secret'] else 'üü¢ –ù–ï –°–ï–ö–†–ï–¢'}")
            print(f"   üìà –ò—Ç–æ–≥–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.1%}")
            print(f"   ‚ö° –°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {result['severity']}")
            print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result['processing_time_ms']} –º—Å")
            
            # –î–µ—Ç–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            details = result.get('prediction_details', {})
            if details.get('averaged_confidence'):
                print(f"\nüìã –î–µ—Ç–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
                print(f"   ‚Ä¢ –¢–µ–∫—Å—Ç: {details['text_confidence']:.1%} ({'—Å–µ–∫—Ä–µ—Ç' if details['text_prediction'] else '–Ω–µ —Å–µ–∫—Ä–µ—Ç'})")
                print(f"   ‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç: {details['context_confidence']:.1%} ({'—Å–µ–∫—Ä–µ—Ç' if details['context_prediction'] else '–Ω–µ —Å–µ–∫—Ä–µ—Ç'})")
                print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ confidence")
            else:
                print(f"\nüìã –î–µ—Ç–∞–ª–∏: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
            
        except KeyboardInterrupt:
            print("\nüëã –í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def console_manager():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
    global logger
    logger = setup_logging(console_mode=True)
    
    print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    
    try:
        classifier = SecretClassifier(console_mode=True)
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
        return
    
    while True:
        show_menu()
        
        try:
            choice = input("\nüî∏ –í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç (1-5): ").strip()
            
            if choice == '1':
                confirm = input("‚ö†Ô∏è  –í—ã —É–≤–µ—Ä–µ–Ω—ã —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å? (y/n): ").strip().lower()
                if confirm in ['y', 'yes', '–¥–∞', '–¥']:
                    classifier.retrain_model()
                else:
                    print("‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
                    
            elif choice == '2':
                show_model_info(classifier)
                
            elif choice == '3':
                test_model(classifier)
                
            elif choice == '4':
                classifier.automatic_test_from_csv()
                
            elif choice == '5':
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
                
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                
        except KeyboardInterrupt:
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    console_manager()